mport os
import streamlit as st
import snowflake.snowpark as snowpark
from langchain_community.document_loaders import PyPDFLoader, PDFPlumberLoader
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.text_splitter import RecursiveCharacterTextSplitter

# âœ… Streamlit ìºì‹œ: VectorStoreëŠ” ìµœì´ˆ í•œ ë²ˆë§Œ ìƒì„±
@st.cache_resource(show_spinner=False)
def load_vectorstore(pdf_path="test manual.pdf"):
    try:
        loader = PDFPlumberLoader(pdf_path)
    except Exception:
        loader = PyPDFLoader(pdf_path)

    documents = loader.load()
    st.write(f"ğŸ“„ PDF í˜ì´ì§€ ìˆ˜: {len(documents)}")

    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=100
    )
    docs = text_splitter.split_documents(documents)
    st.write(f"ğŸ”¹ ë¶„í• ëœ ì²­í¬ ìˆ˜: {len(docs)}")

    embeddings = OpenAIEmbeddings()
    db = FAISS.from_documents(docs, embeddings)
    return db

# âœ… Snowflake Streamlit entry point
def main(session: snowpark.Session):
    st.set_page_config(page_title="ì„¤ê³„ê´€ë¦¬ìë£Œ RAG ì±—ë´‡", page_icon="ğŸ’¡")
    st.title("ğŸ“ ì„¤ê³„ê´€ë¦¬ìë£Œ ê¸°ë°˜ RAG ì±—ë´‡")

    # 1ï¸âƒ£ OpenAI API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
    try:
        openai_key = session.get_secret("openai_api_key")
        os.environ["OPENAI_API_KEY"] = openai_key
        st.success("âœ… OpenAI API Keyê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.error(f"âŒ API Key ë¡œë“œ ì‹¤íŒ¨: {e}")
        st.stop()

    # 2ï¸âƒ£ PDF ê²½ë¡œ ì„¤ì • (Snowflakeì—ì„œëŠ” ë¡œì»¬ ì ‘ê·¼ ë¶ˆê°€)
    pdf_path = "test manual.pdf"

    # 3ï¸âƒ£ VectorStore ë¡œë“œ
    with st.spinner("VectorStore ë¡œë”© ì¤‘..."):
        db = load_vectorstore(pdf_path)

    retriever = db.as_retriever(search_kwargs={"k": 5})

    chat_model = ChatOpenAI(
        model_name="gpt-4o-mini",
        temperature=0
    )

    qa_chain = RetrievalQA.from_chain_type(
        llm=chat_model,
        retriever=retriever,
        chain_type="stuff",
        return_source_documents=True
    )

    query = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
    if query:
        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            result = qa_chain(query)

        st.markdown("### ğŸ’¡ ë‹µë³€")
        st.write(result["result"])

        st.markdown("### ğŸ“š ì°¸ê³  ë¬¸ì„œ")
        for i, doc in enumerate(result["source_documents"], 1):
            st.write(f"--- ë¬¸ì„œ {i} ---")
            st.write(doc.page_content)
